{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd429c85-8c1f-4dff-8676-a7bf819b2c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 10:59:33,351 - Starting the scraper for all products...\n",
      "2025-02-03 10:59:59,527 - Best Sellers Rank for Found It: 2246(13)\n",
      "2025-02-03 10:59:59,527 - Skipping category ranking for Found It, as Best Seller Rank is not (1).\n",
      "C:\\Users\\Suraj Gaikwad\\AppData\\Local\\Temp\\ipykernel_6764\\3658967683.py:66: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
      "  rank_sheet.update('A1', [headers] + data)\n",
      "2025-02-03 11:00:00,578 - Error updating Google Sheet: Out of range float values are not JSON compliant: nan\n",
      "2025-02-03 11:00:07,581 - Best Sellers Rank for poke in art: 66(1)\n",
      "2025-02-03 11:00:11,543 - Opening Category URL: https://www.amazon.com/gp/bestsellers/toys-and-games/166078011/ref=pd_zg_hrsr_toys-and-games\n",
      "2025-02-03 11:00:11,609 - Found subcategory: 1 - https://www.amazon.com/Best-Sellers-Toys-Games-Kids-Wood-Craft-Kits/zgbs/toys-and-games/166078011/ref=zg_bs_pg_1_toys-and-games?_encoding=UTF8&pg=1\n",
      "2025-02-03 11:00:11,631 - Found subcategory: 2 - https://www.amazon.com/Best-Sellers-Toys-Games-Kids-Wood-Craft-Kits/zgbs/toys-and-games/166078011/ref=zg_bs_pg_2_toys-and-games?_encoding=UTF8&pg=2\n",
      "2025-02-03 11:00:11,657 - Found subcategory: Next page - https://www.amazon.com/Best-Sellers-Toys-Games-Kids-Wood-Craft-Kits/zgbs/toys-and-games/166078011/ref=zg_bs_pg_2_toys-and-games?_encoding=UTF8&pg=2\n",
      "2025-02-03 11:00:11,825 - Found subcategory: Arts & Crafts - https://www.amazon.com/Best-Sellers-Toys-Games-Arts-Crafts-Supplies/zgbs/toys-and-games/166057011/ref=zg_bs_unv_toys-and-games_2_166078011_3\n",
      "2025-02-03 11:00:11,885 - Found subcategory: Craft Kits - https://www.amazon.com/Best-Sellers-Toys-Games-Craft-Kits/zgbs/toys-and-games/166064011/ref=zg_bs_unv_toys-and-games_3_166078011_2\n",
      "2025-02-03 11:00:11,921 - Rank for ASIN B0CZP42TND: 1\n",
      "2025-02-03 11:00:12,916 - Opening Subcategory URL: https://www.amazon.com/Best-Sellers-Toys-Games-Kids-Wood-Craft-Kits/zgbs/toys-and-games/166078011/ref=zg_bs_pg_1_toys-and-games?_encoding=UTF8&pg=1 for 1\n",
      "2025-02-03 11:00:12,955 - ASIN B0CZP42TND found on subcategory page: 1\n",
      "2025-02-03 11:00:12,990 - Rank for ASIN B0CZP42TND: 1\n",
      "2025-02-03 11:00:15,880 - Opening Subcategory URL: https://www.amazon.com/Best-Sellers-Toys-Games-Kids-Wood-Craft-Kits/zgbs/toys-and-games/166078011/ref=zg_bs_pg_2_toys-and-games?_encoding=UTF8&pg=2 for 2\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Path to your service account key file\n",
    "SERVICE_ACCOUNT_FILE = 'ranking-436314-4daf4b7d4292.json'\n",
    "\n",
    "# Define the scope\n",
    "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "# Authenticate using the service account file\n",
    "creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Open the Google Sheet\n",
    "workbook = client.open(\"Skillmatics Rank Sheet Streamlit\")\n",
    "url_sheet = workbook.worksheet(\"Node-URL\")\n",
    "rank_sheet = workbook.worksheet(\"Node-Rank\")\n",
    "\n",
    "def current_time_slot():\n",
    "    \"\"\"Returns the current timestamp for tracking scraping sessions.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return now.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "def parse_rank_numbers(rank_text):\n",
    "    \"\"\"Parses the rank text to extract the primary and secondary rankings.\"\"\"\n",
    "    ranks = rank_text.split('\\n')\n",
    "    primary_rank = ranks[0].split()[0].lstrip('#').replace(',', '')\n",
    "    secondary_rank = ranks[1].split()[0].lstrip('#').replace(',', '') if len(ranks) > 1 else ''\n",
    "    return f\"{primary_rank}({secondary_rank})\" if secondary_rank else primary_rank\n",
    "\n",
    "\n",
    "\n",
    "def update_google_sheet(product, current_time, rank_value):\n",
    "    \"\"\"Updates the Google Sheet with the latest rank values efficiently.\"\"\"\n",
    "    try:\n",
    "        # Fetch existing data\n",
    "        existing_data = rank_sheet.get_all_records()\n",
    "        existing_df = pd.DataFrame(existing_data)\n",
    "        existing_df.set_index('Product', inplace=True)\n",
    "\n",
    "        # Create a new DataFrame for the update\n",
    "        update_data = pd.DataFrame({current_time: [rank_value]}, index=[product])\n",
    "\n",
    "        # Merge new data\n",
    "        merged_data = existing_df.combine_first(update_data)\n",
    "\n",
    "        # Convert DataFrame back to list format\n",
    "        data = merged_data.reset_index().values.tolist()\n",
    "        headers = ['Product'] + [col for col in merged_data.columns if col != 'Product']\n",
    "\n",
    "        # Clear and update the sheet in one batch update\n",
    "        rank_sheet.clear()\n",
    "        rank_sheet.update('A1', [headers] + data)\n",
    "\n",
    "        logger.info(f\"Updated Google Sheet: {product} -> {rank_value} at {current_time}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error updating Google Sheet: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def fetch_rank_for_asin(driver, asin):\n",
    "    \"\"\"Fetches the rank for the provided ASIN on the page.\"\"\"\n",
    "    try:\n",
    "        rank_element = driver.find_element(By.XPATH, f\"//div[@data-asin='{asin}']//span[contains(@class, 'zg-bdg-text')]\")\n",
    "        rank_text = rank_element.text.strip().replace('#', '')\n",
    "        logger.info(f\"Rank for ASIN {asin}: {rank_text}\")\n",
    "        return rank_text\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not fetch rank for ASIN {asin}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_rank_in_subcategory(driver, subcategory_url, subcategory_name, asin):\n",
    "    \"\"\"Fetches the rank of the product in a specific subcategory.\"\"\"\n",
    "    try:\n",
    "        driver.get(subcategory_url)\n",
    "        logger.info(f\"Opening Subcategory URL: {subcategory_url} for {subcategory_name}\")\n",
    "\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, f\"//div[@data-asin='{asin}']\"))\n",
    "        )\n",
    "        logger.info(f\"ASIN {asin} found on subcategory page: {subcategory_name}\")\n",
    "\n",
    "        rank = fetch_rank_for_asin(driver, asin)\n",
    "        if rank:\n",
    "            return f\"{rank}\"  # Only return the rank for simplified formatting\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"ASIN {asin} not found or rank unavailable in subcategory {subcategory_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# def fetch_subcategories_and_ranks(driver):\n",
    "#     \"\"\"Fetches the next three subcategories, opens their links, and retrieves rankings.\"\"\"\n",
    "#     try:\n",
    "#         subcategory_elements = driver.find_elements(By.XPATH, \"//a[contains(@href, '/zgbs/')]\")\n",
    "#         subcategories = []\n",
    "#         count = 0\n",
    "\n",
    "#         for element in subcategory_elements:\n",
    "#             try:\n",
    "#                 subcategory_name = element.text.strip()\n",
    "#                 subcategory_link = element.get_attribute(\"href\")\n",
    "\n",
    "#                 # Skip irrelevant categories\n",
    "#                 if all(skip not in subcategory_name for skip in [\"Any Department\", \"Toys & Games\"]) and subcategory_link:\n",
    "#                     subcategories.append((subcategory_name, subcategory_link))\n",
    "#                     logger.info(f\"Found subcategory: {subcategory_name} - {subcategory_link}\")\n",
    "#                     count += 1\n",
    "#                     if count >= 5:  # Limit to 3 subcategories\n",
    "#                         break\n",
    "#             except Exception as e:\n",
    "#                 logger.warning(f\"Error processing subcategory element: {e}\")\n",
    "\n",
    "#         return subcategories\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Failed to fetch subcategories: {e}\")\n",
    "#         return []\n",
    "\n",
    "def fetch_subcategories_and_ranks(driver):\n",
    "    \"\"\"\n",
    "    Fetch the next three subcategories and their rankings after skipping \"Any Department\" and \"Toys & Games\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subcategory_elements = driver.find_elements(By.XPATH, \"//div[@role='treeitem'] | //a[contains(@href, '/zgbs/')]\")\n",
    "        subcategories = []\n",
    "        count = 0\n",
    "\n",
    "        for element in subcategory_elements:\n",
    "            try:\n",
    "                subcategory_name = element.text.strip()\n",
    "                subcategory_link = element.get_attribute(\"href\")\n",
    "\n",
    "                # Skip \"Any Department\", \"Toys & Games\", and similar categories\n",
    "                if all(skip not in subcategory_name for skip in [\"Any Department\", \"Toys & Games\"]) and subcategory_link:\n",
    "                    subcategories.append((subcategory_name, subcategory_link))\n",
    "                    logger.info(f\"Found subcategory: {subcategory_name} - {subcategory_link}\")\n",
    "                    count += 1\n",
    "                    if count >= 5:  # Limit to the next three valid subcategories\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error processing subcategory element: {e}\")\n",
    "\n",
    "        return subcategories\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to fetch subcategories: {e}\")\n",
    "        return []\n",
    "\n",
    "def check_asins_in_category_page(driver, category_url, asin_list):\n",
    "    \"\"\"Check if ASINs exist in the category page and fetch their ranks.\"\"\"\n",
    "    try:\n",
    "        driver.get(category_url)\n",
    "        logger.info(f\"Opening Category URL: {category_url}\")\n",
    "\n",
    "        found_asins = []\n",
    "        subcategories = fetch_subcategories_and_ranks(driver)\n",
    "\n",
    "        for asin in asin_list:\n",
    "            ranks = []\n",
    "            main_rank = fetch_rank_for_asin(driver, asin)\n",
    "            if main_rank:\n",
    "                ranks.append(main_rank)\n",
    "\n",
    "            for subcategory_name, subcategory_link in subcategories:\n",
    "                if subcategory_link:\n",
    "                    sub_rank = fetch_rank_in_subcategory(driver, subcategory_link, subcategory_name, asin)\n",
    "                    if sub_rank:\n",
    "                        ranks.insert(0, sub_rank)\n",
    "\n",
    "            final_rank = \"\".join([f\"({rank})\" for rank in ranks])\n",
    "            found_asins.append((asin, final_rank))\n",
    "\n",
    "        return found_asins, subcategories\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while checking ASINs: {e}\")\n",
    "        return [], []\n",
    "\n",
    "def extract_first_three_numbers(rank_output):\n",
    "    \"\"\"Extracts the first three numbers from the rank output.\"\"\"\n",
    "    matches = re.findall(r'\\d+\\(\\d+\\)|\\(\\d+\\)', rank_output)\n",
    "    logger.debug(f\"Extracted matches: {matches}\")\n",
    "    return \"\".join(matches[:3])\n",
    "\n",
    "def scrape_best_sellers_rank(driver, product, url, asin_list, current_time):\n",
    "    \"\"\"Scrapes the Best Sellers Rank and category ranks for a given product URL and ASINs.\"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        rank_section = WebDriverWait(driver, 80).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//th[contains(text(), 'Best Sellers Rank')]//following-sibling::td\"))\n",
    "        )\n",
    "        rank_text = rank_section.text.strip()\n",
    "        best_seller_rank = parse_rank_numbers(rank_text)\n",
    "        logger.info(f\"Best Sellers Rank for {product}: {best_seller_rank}\")\n",
    "\n",
    "        if best_seller_rank.endswith(\"(1)\"):\n",
    "            category_links = rank_section.find_elements(By.XPATH, \".//a\")\n",
    "            if len(category_links) > 1:\n",
    "                second_category_url = category_links[1].get_attribute(\"href\")\n",
    "                found_asins_with_ranks, subcategories = check_asins_in_category_page(driver, second_category_url, asin_list)\n",
    "\n",
    "                category_ranks = [ranks for asin, ranks in found_asins_with_ranks]\n",
    "                category_ranks_str = f\"({'})('.join(category_ranks[:3])})\" if category_ranks else \"\"\n",
    "                final_rank = f\"{best_seller_rank}{category_ranks_str}\"\n",
    "\n",
    "                formatted_rank = extract_first_three_numbers(final_rank)\n",
    "                logger.info(f\"Final rank for {product} (ASIN: {asin_list[0]}): {formatted_rank}\")\n",
    "                update_google_sheet(product, current_time, formatted_rank)\n",
    "            else:\n",
    "                logger.warning(f\"No second category link found for {product}.\")\n",
    "        else:\n",
    "            logger.info(f\"Skipping category ranking for {product}, as Best Seller Rank is not (1).\")\n",
    "            update_google_sheet(product, current_time, best_seller_rank)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to scrape {product} ({url}): {e}\")\n",
    "\n",
    "def run_scrape_all():\n",
    "    \"\"\"Fetch URLs and ASINs from the URL sheet and scrape rankings for all products.\"\"\"\n",
    "    url_data = url_sheet.get_all_records()\n",
    "    df = pd.DataFrame(url_data)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    product_names = df['Products'].tolist()\n",
    "    url_list = df['URL'].tolist()\n",
    "    asin_list = df['ASIN'].tolist()\n",
    "\n",
    "    current_time = current_time_slot()\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    for product, url, asin in zip(product_names, url_list, asin_list):\n",
    "        scrape_best_sellers_rank(driver, product, url, [asin], current_time)\n",
    "\n",
    "    driver.quit()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Starting the scraper for all products...\")\n",
    "    run_scrape_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d9e63-08b4-4da2-b530-4625a9e18c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b33e47-e167-487c-9e65-6ba1be61a68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d31a60e-b67c-4b1d-9ead-6386a2e1036e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 11:26:35,326 - Starting the scraper for all products...\n",
      "2025-02-03 11:27:06,331 - Best Sellers Rank for Found It: 2246(13)\n",
      "2025-02-03 11:27:06,332 - Skipping category ranking for Found It, as Best Seller Rank is not (1).\n",
      "2025-02-03 11:27:08,513 - Updated Google Sheet: Found It -> 2246(13) at 2025-02-03 11:26\n",
      "2025-02-03 11:27:28,346 - Best Sellers Rank for poke in art: 66(1)\n",
      "2025-02-03 11:27:33,384 - Opening Category URL: https://www.amazon.com/gp/bestsellers/toys-and-games/166078011/ref=pd_zg_hrsr_toys-and-games\n",
      "2025-02-03 11:27:33,438 - Found subcategory: 1 - https://www.amazon.com/Best-Sellers-Toys-Games-Kids-Wood-Craft-Kits/zgbs/toys-and-games/166078011/ref=zg_bs_pg_1_toys-and-games?_encoding=UTF8&pg=1\n",
      "2025-02-03 11:27:33,469 - Found subcategory: 2 - https://www.amazon.com/Best-Sellers-Toys-Games-Kids-Wood-Craft-Kits/zgbs/toys-and-games/166078011/ref=zg_bs_pg_2_toys-and-games?_encoding=UTF8&pg=2\n",
      "2025-02-03 11:27:33,499 - Found subcategory: Next page - https://www.amazon.com/Best-Sellers-Toys-Games-Kids-Wood-Craft-Kits/zgbs/toys-and-games/166078011/ref=zg_bs_pg_2_toys-and-games?_encoding=UTF8&pg=2\n",
      "2025-02-03 11:27:33,632 - Found subcategory: Arts & Crafts - https://www.amazon.com/Best-Sellers-Toys-Games-Arts-Crafts-Supplies/zgbs/toys-and-games/166057011/ref=zg_bs_unv_toys-and-games_2_166078011_3\n",
      "2025-02-03 11:27:33,698 - Found subcategory: Craft Kits - https://www.amazon.com/Best-Sellers-Toys-Games-Craft-Kits/zgbs/toys-and-games/166064011/ref=zg_bs_unv_toys-and-games_3_166078011_2\n",
      "2025-02-03 11:27:33,788 - Rank for ASIN B0CZP42TND: 1\n",
      "2025-02-03 11:27:46,861 - Opening Subcategory URL: https://www.amazon.com/Best-Sellers-Toys-Games-Kids-Wood-Craft-Kits/zgbs/toys-and-games/166078011/ref=zg_bs_pg_1_toys-and-games?_encoding=UTF8&pg=1 for 1\n",
      "2025-02-03 11:27:46,881 - ASIN B0CZP42TND found on subcategory page: 1\n",
      "2025-02-03 11:27:46,909 - Rank for ASIN B0CZP42TND: 1\n",
      "2025-02-03 11:28:03,210 - Opening Subcategory URL: https://www.amazon.com/Best-Sellers-Toys-Games-Kids-Wood-Craft-Kits/zgbs/toys-and-games/166078011/ref=zg_bs_pg_2_toys-and-games?_encoding=UTF8&pg=2 for 2\n",
      "2025-02-03 11:28:33,302 - ASIN B0CZP42TND not found or rank unavailable in subcategory 2: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6B41D02F5+28725]\n",
      "\t(No symbol) [0x00007FF6B4132AE0]\n",
      "\t(No symbol) [0x00007FF6B3FC510A]\n",
      "\t(No symbol) [0x00007FF6B40193D2]\n",
      "\t(No symbol) [0x00007FF6B40195FC]\n",
      "\t(No symbol) [0x00007FF6B4063407]\n",
      "\t(No symbol) [0x00007FF6B403FFEF]\n",
      "\t(No symbol) [0x00007FF6B4060181]\n",
      "\t(No symbol) [0x00007FF6B403FD53]\n",
      "\t(No symbol) [0x00007FF6B400A0E3]\n",
      "\t(No symbol) [0x00007FF6B400B471]\n",
      "\tGetHandleVerifier [0x00007FF6B44FF30D+3366989]\n",
      "\tGetHandleVerifier [0x00007FF6B45112F0+3440688]\n",
      "\tGetHandleVerifier [0x00007FF6B45078FD+3401277]\n",
      "\tGetHandleVerifier [0x00007FF6B429AAAB+858091]\n",
      "\t(No symbol) [0x00007FF6B413E74F]\n",
      "\t(No symbol) [0x00007FF6B413A304]\n",
      "\t(No symbol) [0x00007FF6B413A49D]\n",
      "\t(No symbol) [0x00007FF6B4128B69]\n",
      "\tBaseThreadInitThunk [0x00007FFE5BB7E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFE5D9DBF2C+44]\n",
      "\n",
      "2025-02-03 11:28:34,160 - Opening Subcategory URL: https://www.amazon.com/Best-Sellers-Toys-Games-Kids-Wood-Craft-Kits/zgbs/toys-and-games/166078011/ref=zg_bs_pg_2_toys-and-games?_encoding=UTF8&pg=2 for Next page\n",
      "2025-02-03 11:29:04,198 - ASIN B0CZP42TND not found or rank unavailable in subcategory Next page: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6B41D02F5+28725]\n",
      "\t(No symbol) [0x00007FF6B4132AE0]\n",
      "\t(No symbol) [0x00007FF6B3FC510A]\n",
      "\t(No symbol) [0x00007FF6B40193D2]\n",
      "\t(No symbol) [0x00007FF6B40195FC]\n",
      "\t(No symbol) [0x00007FF6B4063407]\n",
      "\t(No symbol) [0x00007FF6B403FFEF]\n",
      "\t(No symbol) [0x00007FF6B4060181]\n",
      "\t(No symbol) [0x00007FF6B403FD53]\n",
      "\t(No symbol) [0x00007FF6B400A0E3]\n",
      "\t(No symbol) [0x00007FF6B400B471]\n",
      "\tGetHandleVerifier [0x00007FF6B44FF30D+3366989]\n",
      "\tGetHandleVerifier [0x00007FF6B45112F0+3440688]\n",
      "\tGetHandleVerifier [0x00007FF6B45078FD+3401277]\n",
      "\tGetHandleVerifier [0x00007FF6B429AAAB+858091]\n",
      "\t(No symbol) [0x00007FF6B413E74F]\n",
      "\t(No symbol) [0x00007FF6B413A304]\n",
      "\t(No symbol) [0x00007FF6B413A49D]\n",
      "\t(No symbol) [0x00007FF6B4128B69]\n",
      "\tBaseThreadInitThunk [0x00007FFE5BB7E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFE5D9DBF2C+44]\n",
      "\n",
      "2025-02-03 11:29:07,537 - Opening Subcategory URL: https://www.amazon.com/Best-Sellers-Toys-Games-Arts-Crafts-Supplies/zgbs/toys-and-games/166057011/ref=zg_bs_unv_toys-and-games_2_166078011_3 for Arts & Crafts\n",
      "2025-02-03 11:29:07,595 - ASIN B0CZP42TND found on subcategory page: Arts & Crafts\n",
      "2025-02-03 11:29:07,649 - Rank for ASIN B0CZP42TND: 13\n",
      "2025-02-03 11:29:14,514 - Opening Subcategory URL: https://www.amazon.com/Best-Sellers-Toys-Games-Craft-Kits/zgbs/toys-and-games/166064011/ref=zg_bs_unv_toys-and-games_3_166078011_2 for Craft Kits\n",
      "2025-02-03 11:29:14,530 - ASIN B0CZP42TND found on subcategory page: Craft Kits\n",
      "2025-02-03 11:29:14,563 - Rank for ASIN B0CZP42TND: 3\n",
      "2025-02-03 11:29:14,564 - Final rank for poke in art (ASIN: B0CZP42TND): 66(1)(3)(13)\n",
      "2025-02-03 11:29:16,714 - Updated Google Sheet: poke in art -> 66(1)(3)(13) at 2025-02-03 11:26\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Path to your service account key file\n",
    "SERVICE_ACCOUNT_FILE = 'ranking-436314-4daf4b7d4292.json'\n",
    "\n",
    "# Define the scope\n",
    "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "# Authenticate using the service account file\n",
    "creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Open the Google Sheet\n",
    "workbook = client.open(\"Skillmatics Rank Sheet Streamlit\")\n",
    "url_sheet = workbook.worksheet(\"Node-URL\")\n",
    "rank_sheet = workbook.worksheet(\"Node-Rank\")\n",
    "\n",
    "def current_time_slot():\n",
    "    \"\"\"Returns the current timestamp for tracking scraping sessions.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return now.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "def parse_rank_numbers(rank_text):\n",
    "    \"\"\"Parses the rank text to extract the primary and secondary rankings.\"\"\"\n",
    "    ranks = rank_text.split('\\n')\n",
    "    primary_rank = ranks[0].split()[0].lstrip('#').replace(',', '')\n",
    "    secondary_rank = ranks[1].split()[0].lstrip('#').replace(',', '') if len(ranks) > 1 else ''\n",
    "    return f\"{primary_rank}({secondary_rank})\" if secondary_rank else primary_rank\n",
    "\n",
    "\n",
    "\n",
    "# def update_google_sheet(product, current_time, rank_value):\n",
    "#     \"\"\"Updates the Google Sheet with the latest rank values efficiently.\"\"\"\n",
    "#     try:\n",
    "#         # Fetch existing data\n",
    "#         existing_data = rank_sheet.get_all_records()\n",
    "#         existing_df = pd.DataFrame(existing_data)\n",
    "#         existing_df.set_index('Product', inplace=True)\n",
    "\n",
    "#         # Create a new DataFrame for the update\n",
    "#         update_data = pd.DataFrame({current_time: [rank_value]}, index=[product])\n",
    "\n",
    "#         # Merge new data\n",
    "#         merged_data = existing_df.combine_first(update_data)\n",
    "\n",
    "#         # Convert DataFrame back to list format\n",
    "#         data = merged_data.reset_index().values.tolist()\n",
    "#         headers = ['Product'] + [col for col in merged_data.columns if col != 'Product']\n",
    "\n",
    "#         # Clear and update the sheet in one batch update\n",
    "#         rank_sheet.clear()\n",
    "#         rank_sheet.update('A1', [headers] + data)\n",
    "\n",
    "#         logger.info(f\"Updated Google Sheet: {product} -> {rank_value} at {current_time}\")\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Error updating Google Sheet: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def update_google_sheet(product, current_time, rank_value):\n",
    "    \"\"\"Efficiently updates the Google Sheet with new ranking values.\"\"\"\n",
    "    try:\n",
    "        # Fetch existing data\n",
    "        existing_data = rank_sheet.get_all_records()\n",
    "        existing_df = pd.DataFrame(existing_data)\n",
    "        \n",
    "        if 'Product' not in existing_df.columns:\n",
    "            existing_df['Product'] = ''  # Ensure Product column exists\n",
    "        \n",
    "        existing_df.set_index('Product', inplace=True)\n",
    "\n",
    "        # If new column does not exist, create it\n",
    "        if current_time not in existing_df.columns:\n",
    "            existing_df[current_time] = ''\n",
    "\n",
    "        # Update rank for the specific product\n",
    "        existing_df.loc[product, current_time] = rank_value\n",
    "\n",
    "        # Convert DataFrame back to list format\n",
    "        data = existing_df.reset_index().values.tolist()\n",
    "        headers = ['Product'] + [col for col in existing_df.columns if col != 'Product']\n",
    "\n",
    "        # Clear and update the sheet in a batch operation\n",
    "        rank_sheet.clear()\n",
    "        rank_sheet.append_row(headers)\n",
    "        rank_sheet.append_rows(data)\n",
    "\n",
    "        logger.info(f\"Updated Google Sheet: {product} -> {rank_value} at {current_time}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error updating Google Sheet: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def fetch_rank_for_asin(driver, asin):\n",
    "    \"\"\"Fetches the rank for the provided ASIN on the page.\"\"\"\n",
    "    try:\n",
    "        rank_element = driver.find_element(By.XPATH, f\"//div[@data-asin='{asin}']//span[contains(@class, 'zg-bdg-text')]\")\n",
    "        rank_text = rank_element.text.strip().replace('#', '')\n",
    "        logger.info(f\"Rank for ASIN {asin}: {rank_text}\")\n",
    "        return rank_text\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not fetch rank for ASIN {asin}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_rank_in_subcategory(driver, subcategory_url, subcategory_name, asin):\n",
    "    \"\"\"Fetches the rank of the product in a specific subcategory.\"\"\"\n",
    "    try:\n",
    "        driver.get(subcategory_url)\n",
    "        logger.info(f\"Opening Subcategory URL: {subcategory_url} for {subcategory_name}\")\n",
    "\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, f\"//div[@data-asin='{asin}']\"))\n",
    "        )\n",
    "        logger.info(f\"ASIN {asin} found on subcategory page: {subcategory_name}\")\n",
    "\n",
    "        rank = fetch_rank_for_asin(driver, asin)\n",
    "        if rank:\n",
    "            return f\"{rank}\"  # Only return the rank for simplified formatting\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"ASIN {asin} not found or rank unavailable in subcategory {subcategory_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# def fetch_subcategories_and_ranks(driver):\n",
    "#     \"\"\"Fetches the next three subcategories, opens their links, and retrieves rankings.\"\"\"\n",
    "#     try:\n",
    "#         subcategory_elements = driver.find_elements(By.XPATH, \"//a[contains(@href, '/zgbs/')]\")\n",
    "#         subcategories = []\n",
    "#         count = 0\n",
    "\n",
    "#         for element in subcategory_elements:\n",
    "#             try:\n",
    "#                 subcategory_name = element.text.strip()\n",
    "#                 subcategory_link = element.get_attribute(\"href\")\n",
    "\n",
    "#                 # Skip irrelevant categories\n",
    "#                 if all(skip not in subcategory_name for skip in [\"Any Department\", \"Toys & Games\"]) and subcategory_link:\n",
    "#                     subcategories.append((subcategory_name, subcategory_link))\n",
    "#                     logger.info(f\"Found subcategory: {subcategory_name} - {subcategory_link}\")\n",
    "#                     count += 1\n",
    "#                     if count >= 5:  # Limit to 3 subcategories\n",
    "#                         break\n",
    "#             except Exception as e:\n",
    "#                 logger.warning(f\"Error processing subcategory element: {e}\")\n",
    "\n",
    "#         return subcategories\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Failed to fetch subcategories: {e}\")\n",
    "#         return []\n",
    "\n",
    "def fetch_subcategories_and_ranks(driver):\n",
    "    \"\"\"\n",
    "    Fetch the next three subcategories and their rankings after skipping \"Any Department\" and \"Toys & Games\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subcategory_elements = driver.find_elements(By.XPATH, \"//div[@role='treeitem'] | //a[contains(@href, '/zgbs/')]\")\n",
    "        subcategories = []\n",
    "        count = 0\n",
    "\n",
    "        for element in subcategory_elements:\n",
    "            try:\n",
    "                subcategory_name = element.text.strip()\n",
    "                subcategory_link = element.get_attribute(\"href\")\n",
    "\n",
    "                # Skip \"Any Department\", \"Toys & Games\", and similar categories\n",
    "                if all(skip not in subcategory_name for skip in [\"Any Department\", \"Toys & Games\"]) and subcategory_link:\n",
    "                    subcategories.append((subcategory_name, subcategory_link))\n",
    "                    logger.info(f\"Found subcategory: {subcategory_name} - {subcategory_link}\")\n",
    "                    count += 1\n",
    "                    if count >= 5:  # Limit to the next three valid subcategories\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error processing subcategory element: {e}\")\n",
    "\n",
    "        return subcategories\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to fetch subcategories: {e}\")\n",
    "        return []\n",
    "\n",
    "def check_asins_in_category_page(driver, category_url, asin_list):\n",
    "    \"\"\"Check if ASINs exist in the category page and fetch their ranks.\"\"\"\n",
    "    try:\n",
    "        driver.get(category_url)\n",
    "        logger.info(f\"Opening Category URL: {category_url}\")\n",
    "\n",
    "        found_asins = []\n",
    "        subcategories = fetch_subcategories_and_ranks(driver)\n",
    "\n",
    "        for asin in asin_list:\n",
    "            ranks = []\n",
    "            main_rank = fetch_rank_for_asin(driver, asin)\n",
    "            if main_rank:\n",
    "                ranks.append(main_rank)\n",
    "\n",
    "            for subcategory_name, subcategory_link in subcategories:\n",
    "                if subcategory_link:\n",
    "                    sub_rank = fetch_rank_in_subcategory(driver, subcategory_link, subcategory_name, asin)\n",
    "                    if sub_rank:\n",
    "                        ranks.insert(0, sub_rank)\n",
    "\n",
    "            final_rank = \"\".join([f\"({rank})\" for rank in ranks])\n",
    "            found_asins.append((asin, final_rank))\n",
    "\n",
    "        return found_asins, subcategories\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while checking ASINs: {e}\")\n",
    "        return [], []\n",
    "\n",
    "def extract_first_three_numbers(rank_output):\n",
    "    \"\"\"Extracts the first three numbers from the rank output.\"\"\"\n",
    "    matches = re.findall(r'\\d+\\(\\d+\\)|\\(\\d+\\)', rank_output)\n",
    "    logger.debug(f\"Extracted matches: {matches}\")\n",
    "    return \"\".join(matches[:3])\n",
    "\n",
    "def scrape_best_sellers_rank(driver, product, url, asin_list, current_time):\n",
    "    \"\"\"Scrapes the Best Sellers Rank and category ranks for a given product URL and ASINs.\"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        rank_section = WebDriverWait(driver, 80).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//th[contains(text(), 'Best Sellers Rank')]//following-sibling::td\"))\n",
    "        )\n",
    "        rank_text = rank_section.text.strip()\n",
    "        best_seller_rank = parse_rank_numbers(rank_text)\n",
    "        logger.info(f\"Best Sellers Rank for {product}: {best_seller_rank}\")\n",
    "\n",
    "        if best_seller_rank.endswith(\"(1)\"):\n",
    "            category_links = rank_section.find_elements(By.XPATH, \".//a\")\n",
    "            if len(category_links) > 1:\n",
    "                second_category_url = category_links[1].get_attribute(\"href\")\n",
    "                found_asins_with_ranks, subcategories = check_asins_in_category_page(driver, second_category_url, asin_list)\n",
    "\n",
    "                category_ranks = [ranks for asin, ranks in found_asins_with_ranks]\n",
    "                category_ranks_str = f\"({'})('.join(category_ranks[:3])})\" if category_ranks else \"\"\n",
    "                final_rank = f\"{best_seller_rank}{category_ranks_str}\"\n",
    "\n",
    "                formatted_rank = extract_first_three_numbers(final_rank)\n",
    "                logger.info(f\"Final rank for {product} (ASIN: {asin_list[0]}): {formatted_rank}\")\n",
    "                update_google_sheet(product, current_time, formatted_rank)\n",
    "            else:\n",
    "                logger.warning(f\"No second category link found for {product}.\")\n",
    "        else:\n",
    "            logger.info(f\"Skipping category ranking for {product}, as Best Seller Rank is not (1).\")\n",
    "            update_google_sheet(product, current_time, best_seller_rank)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to scrape {product} ({url}): {e}\")\n",
    "\n",
    "def run_scrape_all():\n",
    "    \"\"\"Fetch URLs and ASINs from the URL sheet and scrape rankings for all products.\"\"\"\n",
    "    url_data = url_sheet.get_all_records()\n",
    "    df = pd.DataFrame(url_data)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    product_names = df['Products'].tolist()\n",
    "    url_list = df['URL'].tolist()\n",
    "    asin_list = df['ASIN'].tolist()\n",
    "\n",
    "    current_time = current_time_slot()\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    for product, url, asin in zip(product_names, url_list, asin_list):\n",
    "        scrape_best_sellers_rank(driver, product, url, [asin], current_time)\n",
    "\n",
    "    driver.quit()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Starting the scraper for all products...\")\n",
    "    run_scrape_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8d909-b7c1-429f-8600-c0e2bbaf7c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
