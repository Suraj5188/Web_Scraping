{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cb3577-168f-4a52-87f4-737cb885c8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 15:24:48,460 - Running scraper for a single URL...\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def current_time_slot():\n",
    "    now = datetime.now()\n",
    "    return now.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "def parse_rank_numbers(rank_text):\n",
    "    ranks = rank_text.split('\\n')\n",
    "    primary_rank = ranks[0].split()[0].lstrip('#').replace(',', '')\n",
    "    secondary_rank = ranks[1].split()[0].lstrip('#').replace(',', '') if len(ranks) > 1 else ''\n",
    "    return f\"{primary_rank}({secondary_rank})\" if secondary_rank else primary_rank\n",
    "\n",
    "def fetch_rank_for_asin(driver, asin):\n",
    "    try:\n",
    "        rank_element = driver.find_element(By.XPATH, f\"//div[@data-asin='{asin}']//span[contains(@class, 'zg-bdg-text')]\")\n",
    "        rank_text = rank_element.text.strip().replace('#', '')\n",
    "        logger.info(f\"Rank for ASIN {asin}: {rank_text}\")\n",
    "        return rank_text\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not fetch rank for ASIN {asin}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_rank_in_subcategory(driver, subcategory_url, subcategory_name, asin):\n",
    "    try:\n",
    "        driver.get(subcategory_url)\n",
    "        logger.info(f\"Opening Subcategory URL: {subcategory_url} for {subcategory_name}\")\n",
    "\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, f\"//div[@data-asin='{asin}']\"))\n",
    "        )\n",
    "        logger.info(f\"ASIN {asin} found on subcategory page: {subcategory_name}\")\n",
    "\n",
    "        rank = fetch_rank_for_asin(driver, asin)\n",
    "        if rank:\n",
    "            return f\"{rank}\"  # Only return the rank for simplified formatting\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"ASIN {asin} not found or rank unavailable in subcategory {subcategory_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_subcategories_and_ranks(driver):\n",
    "    \"\"\"\n",
    "    Fetch the next three subcategories and their rankings after skipping \"Any Department\" and \"Toys & Games\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subcategory_elements = driver.find_elements(By.XPATH, \"//div[@role='treeitem'] | //a[contains(@href, '/zgbs/')]\")\n",
    "        subcategories = []\n",
    "        count = 0\n",
    "\n",
    "        for element in subcategory_elements:\n",
    "            try:\n",
    "                subcategory_name = element.text.strip()\n",
    "                subcategory_link = element.get_attribute(\"href\")\n",
    "\n",
    "                # Skip \"Any Department\", \"Toys & Games\", and similar categories\n",
    "                if all(skip not in subcategory_name for skip in [\"Any Department\", \"Toys & Games\"]) and subcategory_link:\n",
    "                    subcategories.append((subcategory_name, subcategory_link))\n",
    "                    logger.info(f\"Found subcategory: {subcategory_name} - {subcategory_link}\")\n",
    "                    count += 1\n",
    "                    if count >= 5:  # Limit to the next three valid subcategories\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error processing subcategory element: {e}\")\n",
    "\n",
    "        return subcategories\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to fetch subcategories: {e}\")\n",
    "        return []\n",
    "\n",
    "def check_asins_in_category_page(driver, category_url, asin_list):\n",
    "    \"\"\"\n",
    "    Check if ASINs exist in the category page and fetch their ranks.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(category_url)\n",
    "        logger.info(f\"Opening Category URL: {category_url}\")\n",
    "\n",
    "        found_asins = []\n",
    "        subcategories = fetch_subcategories_and_ranks(driver)\n",
    "\n",
    "        for asin in asin_list:\n",
    "            ranks = []\n",
    "            main_rank = fetch_rank_for_asin(driver, asin)\n",
    "            if main_rank:\n",
    "                ranks.append(main_rank)  # Append the main category rank last\n",
    "\n",
    "            for subcategory_name, subcategory_link in subcategories:\n",
    "                if subcategory_link:\n",
    "                    sub_rank = fetch_rank_in_subcategory(driver, subcategory_link, subcategory_name, asin)\n",
    "                    if sub_rank:\n",
    "                        ranks.insert(0, sub_rank)  # Insert subcategory ranks at the beginning\n",
    "\n",
    "            final_rank = \" \".join([f\"({rank})\" for rank in ranks])\n",
    "            found_asins.append((asin, final_rank))\n",
    "\n",
    "        return found_asins, subcategories\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while checking ASINs: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# def scrape_best_sellers_rank(driver, product, url, asin_list):\n",
    "#     try:\n",
    "#         driver.get(url)\n",
    "#         rank_section = WebDriverWait(driver, 80).until(\n",
    "#             EC.visibility_of_element_located((By.XPATH, \"//th[contains(text(), 'Best Sellers Rank')]//following-sibling::td\"))\n",
    "#         )\n",
    "#         rank_text = rank_section.text.strip()\n",
    "#         best_seller_rank = parse_rank_numbers(rank_text)\n",
    "#         logger.info(f\"Best Sellers Rank for {product}: {best_seller_rank}\")\n",
    "\n",
    "#         category_links = rank_section.find_elements(By.XPATH, \".//a\")\n",
    "#         if len(category_links) > 1:\n",
    "#             second_category_url = category_links[1].get_attribute(\"href\")\n",
    "#             found_asins_with_ranks, subcategories = check_asins_in_category_page(driver, second_category_url, asin_list)\n",
    "\n",
    "#             # Add the best seller rank to the final output\n",
    "#             for asin, ranks in found_asins_with_ranks:\n",
    "#                 final_output = f\"{best_seller_rank} {ranks}\"\n",
    "#                 logger.info(f\"Final rank output for ASIN {asin}: {final_output}\")\n",
    "#         else:\n",
    "#             logger.warning(f\"No second category link found for {product}.\")\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Failed to scrape {product} ({url}): {e}\")\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def scrape_best_sellers_rank(driver, product, url, asin_list):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        rank_section = WebDriverWait(driver, 20).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//th[contains(text(), 'Best Sellers Rank')]//following-sibling::td\"))\n",
    "        )\n",
    "        rank_text = rank_section.text.strip()\n",
    "        best_seller_rank = parse_rank_numbers(rank_text)\n",
    "        logger.info(f\"Best Sellers Rank for {product}: {best_seller_rank}\")\n",
    "\n",
    "        category_links = rank_section.find_elements(By.XPATH, \".//a\")\n",
    "        if len(category_links) > 1:\n",
    "            second_category_url = category_links[1].get_attribute(\"href\")\n",
    "            found_asins_with_ranks, subcategories = check_asins_in_category_page(driver, second_category_url, asin_list)\n",
    "\n",
    "            # Add the best seller rank to the final output\n",
    "            for asin, ranks in found_asins_with_ranks:\n",
    "                # Debugging: Ensure `ranks` contains full rank information\n",
    "                logger.debug(f\"Raw ranks for ASIN {asin}: {ranks}\")\n",
    "\n",
    "                # Extract the first three numbers\n",
    "                final_output = f\"{best_seller_rank} {ranks}\"\n",
    "                first_three_numbers = extract_first_three_numbers(final_output)\n",
    "\n",
    "                # Log the final output\n",
    "                logger.info(f\"Final rank output for ASIN {asin}: {first_three_numbers}\")\n",
    "        else:\n",
    "            logger.warning(f\"No second category link found for {product}.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to scrape {product} ({url}): {e}\")\n",
    "\n",
    "def extract_first_three_numbers(rank_output):\n",
    "    \"\"\"Extract the first three numbers from the rank output.\"\"\"\n",
    "    # Regular expression to match numbers followed by optional parentheses\n",
    "    # matches = re.findall(r'\\d+\\(.*?\\)', rank_output)\n",
    "\n",
    "    # # Debugging: Log matches for validation\n",
    "    # logger.debug(f\"Extracted matches: {matches}\")\n",
    "\n",
    "    # # Return the first three matches joined with a space\n",
    "    # return \" \".join(matches[:3])\n",
    "\n",
    "    # Regular expression to match numbers with or without leading digits\n",
    "    matches = re.findall(r'\\d+\\(\\d+\\)|\\(\\d+\\)', rank_output)\n",
    "    logger.debug(f\"Extracted matches: {matches}\")\n",
    "    # Return the first three matches joined with a space\n",
    "    return \"\".join(matches[:3])\n",
    "\n",
    "\n",
    "def run_scrape_single_url(product, url, asin_list):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    scrape_best_sellers_rank(driver, product, url, asin_list)\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    product_name = \"Sample Product\"\n",
    "    product_url = \"https://www.amazon.com/Skillmatics-Art-Craft-Activity-Princesses/dp/B0BV2YFF5K/ref=zg_bs_g_166057011_d_sccl_7/138-9322492-1070323?th=1\"\n",
    "    asin_list = [\"B0BV2YFF5K\"]\n",
    "\n",
    "    logger.info(\"Running scraper for a single URL...\")\n",
    "    run_scrape_single_url(product_name, product_url, asin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414df2d-95f8-4b13-8843-e5ce419943eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd1ef4-cccd-4757-89ce-684eeac942e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbe73ac6-3671-42b0-a453-b6b9499f6a03",
   "metadata": {},
   "source": [
    "__Testing On the different url__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f66ddfb2-110b-48f5-a3ec-02353e86c2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 18:52:35,072 - Running scraper for a single URL...\n",
      "2025-01-29 18:52:59,794 - Best Sellers Rank for Sample Product: 41(1)\n",
      "2025-01-29 18:53:00,198 - Opening Category URL: https://www.amazon.com/gp/bestsellers/toys-and-games/166078011/ref=pd_zg_hrsr_toys-and-games\n",
      "2025-01-29 18:53:00,241 - Could not fetch rank for ASIN B0CZP42TND: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@data-asin='B0CZP42TND']//span[contains(@class, 'zg-bdg-text')]\"}\n",
      "  (Session info: chrome=131.0.6778.265); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7491480D5+2992373]\n",
      "\t(No symbol) [0x00007FF748DDBFD0]\n",
      "\t(No symbol) [0x00007FF748C7590A]\n",
      "\t(No symbol) [0x00007FF748CC926E]\n",
      "\t(No symbol) [0x00007FF748CC955C]\n",
      "\t(No symbol) [0x00007FF748D127D7]\n",
      "\t(No symbol) [0x00007FF748CEF3AF]\n",
      "\t(No symbol) [0x00007FF748D0F584]\n",
      "\t(No symbol) [0x00007FF748CEF113]\n",
      "\t(No symbol) [0x00007FF748CBA918]\n",
      "\t(No symbol) [0x00007FF748CBBA81]\n",
      "\tGetHandleVerifier [0x00007FF7491A6A2D+3379789]\n",
      "\tGetHandleVerifier [0x00007FF7491BC32D+3468109]\n",
      "\tGetHandleVerifier [0x00007FF7491B0043+3418211]\n",
      "\tGetHandleVerifier [0x00007FF748F3C78B+847787]\n",
      "\t(No symbol) [0x00007FF748DE757F]\n",
      "\t(No symbol) [0x00007FF748DE2FC4]\n",
      "\t(No symbol) [0x00007FF748DE315D]\n",
      "\t(No symbol) [0x00007FF748DD2979]\n",
      "\tBaseThreadInitThunk [0x00007FF98810E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FF9895FFBCC+44]\n",
      "\n",
      "2025-01-29 18:53:00,242 - Final rank output for ASIN B0CZP42TND: 41(1)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def current_time_slot():\n",
    "    now = datetime.now()\n",
    "    return now.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "def parse_rank_numbers(rank_text):\n",
    "    ranks = rank_text.split('\\n')\n",
    "    primary_rank = ranks[0].split()[0].lstrip('#').replace(',', '')\n",
    "    secondary_rank = ranks[1].split()[0].lstrip('#').replace(',', '') if len(ranks) > 1 else ''\n",
    "    return f\"{primary_rank}({secondary_rank})\" if secondary_rank else primary_rank\n",
    "\n",
    "def fetch_rank_for_asin(driver, asin):\n",
    "    try:\n",
    "        rank_element = driver.find_element(By.XPATH, f\"//div[@data-asin='{asin}']//span[contains(@class, 'zg-bdg-text')]\")\n",
    "        rank_text = rank_element.text.strip().replace('#', '')\n",
    "        logger.info(f\"Rank for ASIN {asin}: {rank_text}\")\n",
    "        return rank_text\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not fetch rank for ASIN {asin}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_rank_in_subcategory(driver, subcategory_url, subcategory_name, asin):\n",
    "    try:\n",
    "        driver.get(subcategory_url)\n",
    "        logger.info(f\"Opening Subcategory URL: {subcategory_url} for {subcategory_name}\")\n",
    "\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, f\"//div[@data-asin='{asin}']\"))\n",
    "        )\n",
    "        logger.info(f\"ASIN {asin} found on subcategory page: {subcategory_name}\")\n",
    "\n",
    "        rank = fetch_rank_for_asin(driver, asin)\n",
    "        if rank:\n",
    "            return f\"{rank}\"  # Only return the rank for simplified formatting\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"ASIN {asin} not found or rank unavailable in subcategory {subcategory_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_subcategories_and_ranks(driver):\n",
    "    \"\"\"\n",
    "    Fetch the next three subcategories and their rankings after skipping \"Any Department\" and \"Toys & Games\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subcategory_elements = driver.find_elements(By.XPATH, \"//div[@role='treeitem'] | //a[contains(@href, '/zgbs/')]\")\n",
    "        subcategories = []\n",
    "        count = 0\n",
    "\n",
    "        for element in subcategory_elements:\n",
    "            try:\n",
    "                subcategory_name = element.text.strip()\n",
    "                subcategory_link = element.get_attribute(\"href\")\n",
    "\n",
    "                # Skip \"Any Department\", \"Toys & Games\", and similar categories\n",
    "                if all(skip not in subcategory_name for skip in [\"Any Department\", \"Toys & Games\"]) and subcategory_link:\n",
    "                    subcategories.append((subcategory_name, subcategory_link))\n",
    "                    logger.info(f\"Found subcategory: {subcategory_name} - {subcategory_link}\")\n",
    "                    count += 1\n",
    "                    if count >= 5:  # Limit to the next three valid subcategories\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error processing subcategory element: {e}\")\n",
    "\n",
    "        return subcategories\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to fetch subcategories: {e}\")\n",
    "        return []\n",
    "\n",
    "def check_asins_in_category_page(driver, category_url, asin_list):\n",
    "    \"\"\"\n",
    "    Check if ASINs exist in the category page and fetch their ranks.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(category_url)\n",
    "        logger.info(f\"Opening Category URL: {category_url}\")\n",
    "\n",
    "        found_asins = []\n",
    "        subcategories = fetch_subcategories_and_ranks(driver)\n",
    "\n",
    "        for asin in asin_list:\n",
    "            ranks = []\n",
    "            main_rank = fetch_rank_for_asin(driver, asin)\n",
    "            if main_rank:\n",
    "                ranks.append(main_rank)  # Append the main category rank last\n",
    "\n",
    "            for subcategory_name, subcategory_link in subcategories:\n",
    "                if subcategory_link:\n",
    "                    sub_rank = fetch_rank_in_subcategory(driver, subcategory_link, subcategory_name, asin)\n",
    "                    if sub_rank:\n",
    "                        ranks.insert(0, sub_rank)  # Insert subcategory ranks at the beginning\n",
    "\n",
    "            final_rank = \" \".join([f\"({rank})\" for rank in ranks])\n",
    "            found_asins.append((asin, final_rank))\n",
    "\n",
    "        return found_asins, subcategories\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while checking ASINs: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# def scrape_best_sellers_rank(driver, product, url, asin_list):\n",
    "#     try:\n",
    "#         driver.get(url)\n",
    "#         rank_section = WebDriverWait(driver, 80).until(\n",
    "#             EC.visibility_of_element_located((By.XPATH, \"//th[contains(text(), 'Best Sellers Rank')]//following-sibling::td\"))\n",
    "#         )\n",
    "#         rank_text = rank_section.text.strip()\n",
    "#         best_seller_rank = parse_rank_numbers(rank_text)\n",
    "#         logger.info(f\"Best Sellers Rank for {product}: {best_seller_rank}\")\n",
    "\n",
    "#         category_links = rank_section.find_elements(By.XPATH, \".//a\")\n",
    "#         if len(category_links) > 1:\n",
    "#             second_category_url = category_links[1].get_attribute(\"href\")\n",
    "#             found_asins_with_ranks, subcategories = check_asins_in_category_page(driver, second_category_url, asin_list)\n",
    "\n",
    "#             # Add the best seller rank to the final output\n",
    "#             for asin, ranks in found_asins_with_ranks:\n",
    "#                 final_output = f\"{best_seller_rank} {ranks}\"\n",
    "#                 logger.info(f\"Final rank output for ASIN {asin}: {final_output}\")\n",
    "#         else:\n",
    "#             logger.warning(f\"No second category link found for {product}.\")\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Failed to scrape {product} ({url}): {e}\")\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def scrape_best_sellers_rank(driver, product, url, asin_list):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        rank_section = WebDriverWait(driver, 80).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//th[contains(text(), 'Best Sellers Rank')]//following-sibling::td\"))\n",
    "        )\n",
    "        rank_text = rank_section.text.strip()\n",
    "        best_seller_rank = parse_rank_numbers(rank_text)\n",
    "        logger.info(f\"Best Sellers Rank for {product}: {best_seller_rank}\")\n",
    "\n",
    "        category_links = rank_section.find_elements(By.XPATH, \".//a\")\n",
    "        if len(category_links) > 1:\n",
    "            second_category_url = category_links[1].get_attribute(\"href\")\n",
    "            found_asins_with_ranks, subcategories = check_asins_in_category_page(driver, second_category_url, asin_list)\n",
    "\n",
    "            # Add the best seller rank to the final output\n",
    "            for asin, ranks in found_asins_with_ranks:\n",
    "                # Debugging: Ensure `ranks` contains full rank information\n",
    "                logger.debug(f\"Raw ranks for ASIN {asin}: {ranks}\")\n",
    "\n",
    "                # Extract the first three numbers\n",
    "                final_output = f\"{best_seller_rank} {ranks}\"\n",
    "                first_three_numbers = extract_first_three_numbers(final_output)\n",
    "\n",
    "                # Log the final output\n",
    "                logger.info(f\"Final rank output for ASIN {asin}: {first_three_numbers}\")\n",
    "        else:\n",
    "            logger.warning(f\"No second category link found for {product}.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to scrape {product} ({url}): {e}\")\n",
    "\n",
    "def extract_first_three_numbers(rank_output):\n",
    "    \"\"\"Extract the first three numbers from the rank output.\"\"\"\n",
    "    # Regular expression to match numbers followed by optional parentheses\n",
    "    # matches = re.findall(r'\\d+\\(.*?\\)', rank_output)\n",
    "\n",
    "    # # Debugging: Log matches for validation\n",
    "    # logger.debug(f\"Extracted matches: {matches}\")\n",
    "\n",
    "    # # Return the first three matches joined with a space\n",
    "    # return \" \".join(matches[:3])\n",
    "\n",
    "    # Regular expression to match numbers with or without leading digits\n",
    "    matches = re.findall(r'\\d+\\(\\d+\\)|\\(\\d+\\)', rank_output)\n",
    "    logger.debug(f\"Extracted matches: {matches}\")\n",
    "    # Return the first three matches joined with a space\n",
    "    return \"\".join(matches[:3])\n",
    "\n",
    "\n",
    "def run_scrape_single_url(product, url, asin_list):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "    # options = Options()\n",
    "    # options.add_argument(\"--disable-gpu\")\n",
    "    # options.add_argument(\"--no-sandbox\")\n",
    "    # options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    # options.add_argument(\"--log-level=3\")\n",
    "    # options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    # options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "    # options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    # options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "    # Open driver\n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    # driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    # Random delay before each request\n",
    "    # import random, time\n",
    "    # sleep_time = random.uniform(5, 15)\n",
    "    # logger.info(f\"Sleeping for {sleep_time:.2f} seconds before accessing {url}\")\n",
    "    # time.sleep(sleep_time)\n",
    "    # driver.get(url)\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    scrape_best_sellers_rank(driver, product, url, asin_list)\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    product_name = \"Sample Product\"\n",
    "    product_url = \"https://www.amazon.com/Skillmatics-Art-Craft-Activity-Poke/dp/B0CXTJ9JHK?ref_=ast_sto_dp&th=1\"\n",
    "    asin_list = [\"B0CZP42TND\"]\n",
    "\n",
    "    logger.info(\"Running scraper for a single URL...\")\n",
    "    run_scrape_single_url(product_name, product_url, asin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1dfa8af-3455-4707-9a07-8aaeade338c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 09:47:05,126 - Starting the scraper for all products...\n",
      "2025-02-03 09:47:14,137 - Fetching Poke In Art: Attempt 1\n",
      "2025-02-03 09:47:33,424 - Best Sellers Rank for Poke In Art: 66(1)\n",
      "2025-02-03 09:47:33,535 - Checking category: See Top 100 in Toys & Games -> https://www.amazon.com/gp/bestsellers/toys-and-games/ref=pd_zg_ts_toys-and-games\n",
      "2025-02-03 09:47:36,897 - Opening Subcategory URL: https://www.amazon.com/gp/bestsellers/toys-and-games/ref=pd_zg_ts_toys-and-games for See Top 100 in Toys & Games\n",
      "2025-02-03 09:48:07,049 - ASIN B0CZP42TND not found or rank unavailable in subcategory See Top 100 in Toys & Games: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF63BC102F5+28725]\n",
      "\t(No symbol) [0x00007FF63BB72AE0]\n",
      "\t(No symbol) [0x00007FF63BA0510A]\n",
      "\t(No symbol) [0x00007FF63BA593D2]\n",
      "\t(No symbol) [0x00007FF63BA595FC]\n",
      "\t(No symbol) [0x00007FF63BAA3407]\n",
      "\t(No symbol) [0x00007FF63BA7FFEF]\n",
      "\t(No symbol) [0x00007FF63BAA0181]\n",
      "\t(No symbol) [0x00007FF63BA7FD53]\n",
      "\t(No symbol) [0x00007FF63BA4A0E3]\n",
      "\t(No symbol) [0x00007FF63BA4B471]\n",
      "\tGetHandleVerifier [0x00007FF63BF3F30D+3366989]\n",
      "\tGetHandleVerifier [0x00007FF63BF512F0+3440688]\n",
      "\tGetHandleVerifier [0x00007FF63BF478FD+3401277]\n",
      "\tGetHandleVerifier [0x00007FF63BCDAAAB+858091]\n",
      "\t(No symbol) [0x00007FF63BB7E74F]\n",
      "\t(No symbol) [0x00007FF63BB7A304]\n",
      "\t(No symbol) [0x00007FF63BB7A49D]\n",
      "\t(No symbol) [0x00007FF63BB68B69]\n",
      "\tBaseThreadInitThunk [0x00007FFE5BB7E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFE5D9DBF2C+44]\n",
      "\n",
      "2025-02-03 09:48:07,058 - Attempt 1 failed for Poke In Art: Message: stale element reference: stale element not found\n",
      "  (Session info: chrome=132.0.6834.160); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF63BC102F5+28725]\n",
      "\t(No symbol) [0x00007FF63BB72AE0]\n",
      "\t(No symbol) [0x00007FF63BA0510A]\n",
      "\t(No symbol) [0x00007FF63BA198C4]\n",
      "\t(No symbol) [0x00007FF63BA183D1]\n",
      "\t(No symbol) [0x00007FF63BA0CA89]\n",
      "\t(No symbol) [0x00007FF63BA0CC03]\n",
      "\t(No symbol) [0x00007FF63BA0A7E2]\n",
      "\t(No symbol) [0x00007FF63BA0EDF8]\n",
      "\t(No symbol) [0x00007FF63BAA1460]\n",
      "\t(No symbol) [0x00007FF63BA7FFAA]\n",
      "\t(No symbol) [0x00007FF63BAA0181]\n",
      "\t(No symbol) [0x00007FF63BA7FD53]\n",
      "\t(No symbol) [0x00007FF63BA4A0E3]\n",
      "\t(No symbol) [0x00007FF63BA4B471]\n",
      "\tGetHandleVerifier [0x00007FF63BF3F30D+3366989]\n",
      "\tGetHandleVerifier [0x00007FF63BF512F0+3440688]\n",
      "\tGetHandleVerifier [0x00007FF63BF478FD+3401277]\n",
      "\tGetHandleVerifier [0x00007FF63BCDAAAB+858091]\n",
      "\t(No symbol) [0x00007FF63BB7E74F]\n",
      "\t(No symbol) [0x00007FF63BB7A304]\n",
      "\t(No symbol) [0x00007FF63BB7A49D]\n",
      "\t(No symbol) [0x00007FF63BB68B69]\n",
      "\tBaseThreadInitThunk [0x00007FFE5BB7E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFE5D9DBF2C+44]\n",
      "\n",
      "2025-02-03 09:48:07,059 - Refreshing Poke In Art page and retrying...\n",
      "2025-02-03 09:48:12,218 - Fetching Poke In Art: Attempt 2\n",
      "2025-02-03 09:48:12,420 - Best Sellers Rank for Poke In Art: 66(1)\n",
      "2025-02-03 09:48:12,547 - Checking category: See Top 100 in Toys & Games -> https://www.amazon.com/gp/bestsellers/toys-and-games/ref=pd_zg_ts_toys-and-games\n",
      "2025-02-03 09:48:13,884 - Opening Subcategory URL: https://www.amazon.com/gp/bestsellers/toys-and-games/ref=pd_zg_ts_toys-and-games for See Top 100 in Toys & Games\n",
      "2025-02-03 09:48:43,937 - ASIN B0CZP42TND not found or rank unavailable in subcategory See Top 100 in Toys & Games: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF63BC102F5+28725]\n",
      "\t(No symbol) [0x00007FF63BB72AE0]\n",
      "\t(No symbol) [0x00007FF63BA0510A]\n",
      "\t(No symbol) [0x00007FF63BA593D2]\n",
      "\t(No symbol) [0x00007FF63BA595FC]\n",
      "\t(No symbol) [0x00007FF63BAA3407]\n",
      "\t(No symbol) [0x00007FF63BA7FFEF]\n",
      "\t(No symbol) [0x00007FF63BAA0181]\n",
      "\t(No symbol) [0x00007FF63BA7FD53]\n",
      "\t(No symbol) [0x00007FF63BA4A0E3]\n",
      "\t(No symbol) [0x00007FF63BA4B471]\n",
      "\tGetHandleVerifier [0x00007FF63BF3F30D+3366989]\n",
      "\tGetHandleVerifier [0x00007FF63BF512F0+3440688]\n",
      "\tGetHandleVerifier [0x00007FF63BF478FD+3401277]\n",
      "\tGetHandleVerifier [0x00007FF63BCDAAAB+858091]\n",
      "\t(No symbol) [0x00007FF63BB7E74F]\n",
      "\t(No symbol) [0x00007FF63BB7A304]\n",
      "\t(No symbol) [0x00007FF63BB7A49D]\n",
      "\t(No symbol) [0x00007FF63BB68B69]\n",
      "\tBaseThreadInitThunk [0x00007FFE5BB7E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFE5D9DBF2C+44]\n",
      "\n",
      "2025-02-03 09:48:43,947 - Attempt 2 failed for Poke In Art: Message: stale element reference: stale element not found\n",
      "  (Session info: chrome=132.0.6834.160); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF63BC102F5+28725]\n",
      "\t(No symbol) [0x00007FF63BB72AE0]\n",
      "\t(No symbol) [0x00007FF63BA0510A]\n",
      "\t(No symbol) [0x00007FF63BA198C4]\n",
      "\t(No symbol) [0x00007FF63BA183D1]\n",
      "\t(No symbol) [0x00007FF63BA0CA89]\n",
      "\t(No symbol) [0x00007FF63BA0CC03]\n",
      "\t(No symbol) [0x00007FF63BA0A7E2]\n",
      "\t(No symbol) [0x00007FF63BA0EDF8]\n",
      "\t(No symbol) [0x00007FF63BAA1460]\n",
      "\t(No symbol) [0x00007FF63BA7FFAA]\n",
      "\t(No symbol) [0x00007FF63BAA0181]\n",
      "\t(No symbol) [0x00007FF63BA7FD53]\n",
      "\t(No symbol) [0x00007FF63BA4A0E3]\n",
      "\t(No symbol) [0x00007FF63BA4B471]\n",
      "\tGetHandleVerifier [0x00007FF63BF3F30D+3366989]\n",
      "\tGetHandleVerifier [0x00007FF63BF512F0+3440688]\n",
      "\tGetHandleVerifier [0x00007FF63BF478FD+3401277]\n",
      "\tGetHandleVerifier [0x00007FF63BCDAAAB+858091]\n",
      "\t(No symbol) [0x00007FF63BB7E74F]\n",
      "\t(No symbol) [0x00007FF63BB7A304]\n",
      "\t(No symbol) [0x00007FF63BB7A49D]\n",
      "\t(No symbol) [0x00007FF63BB68B69]\n",
      "\tBaseThreadInitThunk [0x00007FFE5BB7E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFE5D9DBF2C+44]\n",
      "\n",
      "2025-02-03 09:48:43,949 - Refreshing Poke In Art page and retrying...\n",
      "2025-02-03 09:48:48,930 - Fetching Poke In Art: Attempt 3\n",
      "2025-02-03 09:48:49,243 - Best Sellers Rank for Poke In Art: 66(1)\n",
      "2025-02-03 09:48:49,321 - Checking category: See Top 100 in Toys & Games -> https://www.amazon.com/gp/bestsellers/toys-and-games/ref=pd_zg_ts_toys-and-games\n",
      "2025-02-03 09:48:50,355 - Opening Subcategory URL: https://www.amazon.com/gp/bestsellers/toys-and-games/ref=pd_zg_ts_toys-and-games for See Top 100 in Toys & Games\n",
      "2025-02-03 09:49:20,390 - ASIN B0CZP42TND not found or rank unavailable in subcategory See Top 100 in Toys & Games: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF63BC102F5+28725]\n",
      "\t(No symbol) [0x00007FF63BB72AE0]\n",
      "\t(No symbol) [0x00007FF63BA0510A]\n",
      "\t(No symbol) [0x00007FF63BA593D2]\n",
      "\t(No symbol) [0x00007FF63BA595FC]\n",
      "\t(No symbol) [0x00007FF63BAA3407]\n",
      "\t(No symbol) [0x00007FF63BA7FFEF]\n",
      "\t(No symbol) [0x00007FF63BAA0181]\n",
      "\t(No symbol) [0x00007FF63BA7FD53]\n",
      "\t(No symbol) [0x00007FF63BA4A0E3]\n",
      "\t(No symbol) [0x00007FF63BA4B471]\n",
      "\tGetHandleVerifier [0x00007FF63BF3F30D+3366989]\n",
      "\tGetHandleVerifier [0x00007FF63BF512F0+3440688]\n",
      "\tGetHandleVerifier [0x00007FF63BF478FD+3401277]\n",
      "\tGetHandleVerifier [0x00007FF63BCDAAAB+858091]\n",
      "\t(No symbol) [0x00007FF63BB7E74F]\n",
      "\t(No symbol) [0x00007FF63BB7A304]\n",
      "\t(No symbol) [0x00007FF63BB7A49D]\n",
      "\t(No symbol) [0x00007FF63BB68B69]\n",
      "\tBaseThreadInitThunk [0x00007FFE5BB7E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFE5D9DBF2C+44]\n",
      "\n",
      "2025-02-03 09:49:20,399 - Attempt 3 failed for Poke In Art: Message: stale element reference: stale element not found\n",
      "  (Session info: chrome=132.0.6834.160); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF63BC102F5+28725]\n",
      "\t(No symbol) [0x00007FF63BB72AE0]\n",
      "\t(No symbol) [0x00007FF63BA0510A]\n",
      "\t(No symbol) [0x00007FF63BA198C4]\n",
      "\t(No symbol) [0x00007FF63BA183D1]\n",
      "\t(No symbol) [0x00007FF63BA0CA89]\n",
      "\t(No symbol) [0x00007FF63BA0CC03]\n",
      "\t(No symbol) [0x00007FF63BA0A7E2]\n",
      "\t(No symbol) [0x00007FF63BA0EDF8]\n",
      "\t(No symbol) [0x00007FF63BAA1460]\n",
      "\t(No symbol) [0x00007FF63BA7FFAA]\n",
      "\t(No symbol) [0x00007FF63BAA0181]\n",
      "\t(No symbol) [0x00007FF63BA7FD53]\n",
      "\t(No symbol) [0x00007FF63BA4A0E3]\n",
      "\t(No symbol) [0x00007FF63BA4B471]\n",
      "\tGetHandleVerifier [0x00007FF63BF3F30D+3366989]\n",
      "\tGetHandleVerifier [0x00007FF63BF512F0+3440688]\n",
      "\tGetHandleVerifier [0x00007FF63BF478FD+3401277]\n",
      "\tGetHandleVerifier [0x00007FF63BCDAAAB+858091]\n",
      "\t(No symbol) [0x00007FF63BB7E74F]\n",
      "\t(No symbol) [0x00007FF63BB7A304]\n",
      "\t(No symbol) [0x00007FF63BB7A49D]\n",
      "\t(No symbol) [0x00007FF63BB68B69]\n",
      "\tBaseThreadInitThunk [0x00007FFE5BB7E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFE5D9DBF2C+44]\n",
      "\n",
      "2025-02-03 09:49:20,400 - Failed to scrape Poke In Art after 3 retries.\n",
      "C:\\Users\\Suraj Gaikwad\\AppData\\Local\\Temp\\ipykernel_26456\\1071955585.py:66: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
      "  rank_sheet.update('A1', [headers] + data)\n",
      "2025-02-03 09:49:22,133 - Updated Google Sheet: Poke In Art -> Failed to Fetch at 2025-02-03 09:47\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Path to your service account key file\n",
    "SERVICE_ACCOUNT_FILE = 'ranking-436314-4daf4b7d4292.json'\n",
    "\n",
    "# Define the scope\n",
    "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "# Authenticate using the service account file\n",
    "creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Open the Google Sheet\n",
    "workbook = client.open(\"Skillmatics Rank Sheet Streamlit\")\n",
    "url_sheet = workbook.worksheet(\"Node-URL\")\n",
    "rank_sheet = workbook.worksheet(\"Node-Rank\")\n",
    "\n",
    "def current_time_slot():\n",
    "    \"\"\"Returns the current timestamp for tracking scraping sessions.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return now.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "def parse_rank_numbers(rank_text):\n",
    "    \"\"\"Parses the rank text to extract the primary and secondary rankings.\"\"\"\n",
    "    ranks = rank_text.split('\\n')\n",
    "    primary_rank = ranks[0].split()[0].lstrip('#').replace(',', '')\n",
    "    secondary_rank = ranks[1].split()[0].lstrip('#').replace(',', '') if len(ranks) > 1 else ''\n",
    "    return f\"{primary_rank}({secondary_rank})\" if secondary_rank else primary_rank\n",
    "\n",
    "\n",
    "\n",
    "def update_google_sheet(product, current_time, rank_value):\n",
    "    \"\"\"Updates the Google Sheet with the latest rank values efficiently.\"\"\"\n",
    "    try:\n",
    "        # Fetch existing data\n",
    "        existing_data = rank_sheet.get_all_records()\n",
    "        existing_df = pd.DataFrame(existing_data)\n",
    "        existing_df.set_index('Product', inplace=True)\n",
    "\n",
    "        # Create a new DataFrame for the update\n",
    "        update_data = pd.DataFrame({current_time: [rank_value]}, index=[product])\n",
    "\n",
    "        # Merge new data\n",
    "        merged_data = existing_df.combine_first(update_data)\n",
    "\n",
    "        # Convert DataFrame back to list format\n",
    "        data = merged_data.reset_index().values.tolist()\n",
    "        headers = ['Product'] + [col for col in merged_data.columns if col != 'Product']\n",
    "\n",
    "        # Clear and update the sheet in one batch update\n",
    "        rank_sheet.clear()\n",
    "        rank_sheet.update('A1', [headers] + data)\n",
    "\n",
    "        logger.info(f\"Updated Google Sheet: {product} -> {rank_value} at {current_time}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error updating Google Sheet: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def fetch_rank_for_asin(driver, asin):\n",
    "    \"\"\"Fetches the rank for the provided ASIN on the page.\"\"\"\n",
    "    try:\n",
    "        rank_element = driver.find_element(By.XPATH, f\"//div[@data-asin='{asin}']//span[contains(@class, 'zg-bdg-text')]\")\n",
    "        rank_text = rank_element.text.strip().replace('#', '')\n",
    "        logger.info(f\"Rank for ASIN {asin}: {rank_text}\")\n",
    "        return rank_text\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not fetch rank for ASIN {asin}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_rank_in_subcategory(driver, subcategory_url, subcategory_name, asin):\n",
    "    \"\"\"Fetches the rank of the product in a specific subcategory.\"\"\"\n",
    "    try:\n",
    "        driver.get(subcategory_url)\n",
    "        logger.info(f\"Opening Subcategory URL: {subcategory_url} for {subcategory_name}\")\n",
    "\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, f\"//div[@data-asin='{asin}']\"))\n",
    "        )\n",
    "        logger.info(f\"ASIN {asin} found on subcategory page: {subcategory_name}\")\n",
    "\n",
    "        rank = fetch_rank_for_asin(driver, asin)\n",
    "        if rank:\n",
    "            return f\"{rank}\"  # Only return the rank for simplified formatting\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"ASIN {asin} not found or rank unavailable in subcategory {subcategory_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# def fetch_subcategories_and_ranks(driver):\n",
    "#     \"\"\"Fetches the next three subcategories, opens their links, and retrieves rankings.\"\"\"\n",
    "#     try:\n",
    "#         subcategory_elements = driver.find_elements(By.XPATH, \"//a[contains(@href, '/zgbs/')]\")\n",
    "#         subcategories = []\n",
    "#         count = 0\n",
    "\n",
    "#         for element in subcategory_elements:\n",
    "#             try:\n",
    "#                 subcategory_name = element.text.strip()\n",
    "#                 subcategory_link = element.get_attribute(\"href\")\n",
    "\n",
    "#                 # Skip irrelevant categories\n",
    "#                 if all(skip not in subcategory_name for skip in [\"Any Department\", \"Toys & Games\"]) and subcategory_link:\n",
    "#                     subcategories.append((subcategory_name, subcategory_link))\n",
    "#                     logger.info(f\"Found subcategory: {subcategory_name} - {subcategory_link}\")\n",
    "#                     count += 1\n",
    "#                     if count >= 5:  # Limit to 3 subcategories\n",
    "#                         break\n",
    "#             except Exception as e:\n",
    "#                 logger.warning(f\"Error processing subcategory element: {e}\")\n",
    "\n",
    "#         return subcategories\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Failed to fetch subcategories: {e}\")\n",
    "#         return []\n",
    "\n",
    "def fetch_subcategories_and_ranks(driver):\n",
    "    \"\"\"\n",
    "    Fetch the next three subcategories and their rankings after skipping \"Any Department\" and \"Toys & Games\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subcategory_elements = driver.find_elements(By.XPATH, \"//div[@role='treeitem'] | //a[contains(@href, '/zgbs/')]\")\n",
    "        subcategories = []\n",
    "        count = 0\n",
    "\n",
    "        for element in subcategory_elements:\n",
    "            try:\n",
    "                subcategory_name = element.text.strip()\n",
    "                subcategory_link = element.get_attribute(\"href\")\n",
    "\n",
    "                # Skip \"Any Department\", \"Toys & Games\", and similar categories\n",
    "                if all(skip not in subcategory_name for skip in [\"Any Department\", \"Toys & Games\"]) and subcategory_link:\n",
    "                    subcategories.append((subcategory_name, subcategory_link))\n",
    "                    logger.info(f\"Found subcategory: {subcategory_name} - {subcategory_link}\")\n",
    "                    count += 1\n",
    "                    if count >= 5:  # Limit to the next three valid subcategories\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error processing subcategory element: {e}\")\n",
    "\n",
    "        return subcategories\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to fetch subcategories: {e}\")\n",
    "        return []\n",
    "\n",
    "def check_asins_in_category_page(driver, category_url, asin_list):\n",
    "    \"\"\"Check if ASINs exist in the category page and fetch their ranks.\"\"\"\n",
    "    try:\n",
    "        driver.get(category_url)\n",
    "        logger.info(f\"Opening Category URL: {category_url}\")\n",
    "\n",
    "        found_asins = []\n",
    "        subcategories = fetch_subcategories_and_ranks(driver)\n",
    "\n",
    "        for asin in asin_list:\n",
    "            ranks = []\n",
    "            main_rank = fetch_rank_for_asin(driver, asin)\n",
    "            if main_rank:\n",
    "                ranks.append(main_rank)\n",
    "\n",
    "            for subcategory_name, subcategory_link in subcategories:\n",
    "                if subcategory_link:\n",
    "                    sub_rank = fetch_rank_in_subcategory(driver, subcategory_link, subcategory_name, asin)\n",
    "                    if sub_rank:\n",
    "                        ranks.insert(0, sub_rank)\n",
    "\n",
    "            final_rank = \"\".join([f\"({rank})\" for rank in ranks])\n",
    "            found_asins.append((asin, final_rank))\n",
    "\n",
    "        return found_asins, subcategories\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while checking ASINs: {e}\")\n",
    "        return [], []\n",
    "\n",
    "def extract_first_three_numbers(rank_output):\n",
    "    \"\"\"Extracts the first three numbers from the rank output.\"\"\"\n",
    "    matches = re.findall(r'\\d+\\(\\d+\\)|\\(\\d+\\)', rank_output)\n",
    "    logger.debug(f\"Extracted matches: {matches}\")\n",
    "    return \"\".join(matches[:3])\n",
    "\n",
    "# def scrape_best_sellers_rank(driver, product, url, asin_list, current_time):\n",
    "#     \"\"\"Scrapes the Best Sellers Rank and category ranks for a given product URL and ASINs.\"\"\"\n",
    "#     try:\n",
    "#         driver.get(url)\n",
    "#         rank_section = WebDriverWait(driver, 80).until(\n",
    "#             EC.visibility_of_element_located((By.XPATH, \"//th[contains(text(), 'Best Sellers Rank')]//following-sibling::td\"))\n",
    "#         )\n",
    "#         rank_text = rank_section.text.strip()\n",
    "#         best_seller_rank = parse_rank_numbers(rank_text)\n",
    "#         logger.info(f\"Best Sellers Rank for {product}: {best_seller_rank}\")\n",
    "\n",
    "#         if best_seller_rank.endswith(\"(1)\"):\n",
    "#             category_links = rank_section.find_elements(By.XPATH, \".//a\")\n",
    "#             if len(category_links) > 1:\n",
    "#                 second_category_url = category_links[1].get_attribute(\"href\")\n",
    "#                 found_asins_with_ranks, subcategories = check_asins_in_category_page(driver, second_category_url, asin_list)\n",
    "\n",
    "#                 category_ranks = [ranks for asin, ranks in found_asins_with_ranks]\n",
    "#                 category_ranks_str = f\"({'})('.join(category_ranks[:3])})\" if category_ranks else \"\"\n",
    "#                 final_rank = f\"{best_seller_rank}{category_ranks_str}\"\n",
    "\n",
    "#                 formatted_rank = extract_first_three_numbers(final_rank)\n",
    "#                 logger.info(f\"Final rank for {product} (ASIN: {asin_list[0]}): {formatted_rank}\")\n",
    "#                 update_google_sheet(product, current_time, formatted_rank)\n",
    "#             else:\n",
    "#                 logger.warning(f\"No second category link found for {product}.\")\n",
    "#         else:\n",
    "#             logger.info(f\"Skipping category ranking for {product}, as Best Seller Rank is not (1).\")\n",
    "#             update_google_sheet(product, current_time, best_seller_rank)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Failed to scrape {product} ({url}): {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def scrape_best_sellers_rank(driver, product, url, asin_list, current_time):\n",
    "    \"\"\"Scrapes the Best Sellers Rank and category ranks for a given product URL and ASINs.\"\"\"\n",
    "    max_retries = 3  # Maximum retries for throttling\n",
    "    retries = 0\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            # If the current page is already open, just refresh instead of loading again\n",
    "            if driver.current_url != url:\n",
    "                driver.get(url)\n",
    "            else:\n",
    "                logger.info(f\"Refreshing already opened page for {product}\")\n",
    "                driver.refresh()\n",
    "\n",
    "            logger.info(f\"Fetching {product}: Attempt {retries + 1}\")\n",
    "\n",
    "            # Wait for rank section to be visible\n",
    "            rank_section = WebDriverWait(driver, 30).until(\n",
    "                EC.visibility_of_element_located((By.XPATH, \"//th[contains(text(), 'Best Sellers Rank')]//following-sibling::td\"))\n",
    "            )\n",
    "\n",
    "            rank_text = rank_section.text.strip()\n",
    "            best_seller_rank = parse_rank_numbers(rank_text)\n",
    "            logger.info(f\"Best Sellers Rank for {product}: {best_seller_rank}\")\n",
    "\n",
    "            # If no rank is found or throttle detected, refresh and retry\n",
    "            if not best_seller_rank or \"throttle\" in rank_text.lower():\n",
    "                raise Exception(\"Throttle detected, retrying with refresh...\")\n",
    "\n",
    "            category_links = rank_section.find_elements(By.XPATH, \".//a\")\n",
    "            category_ranks = []\n",
    "\n",
    "            if category_links:\n",
    "                for link in category_links[:3]:  # Limit to first 3 category links\n",
    "                    category_url = link.get_attribute(\"href\")\n",
    "                    category_name = link.text.strip()\n",
    "                    logger.info(f\"Checking category: {category_name} -> {category_url}\")\n",
    "\n",
    "                    if category_url:\n",
    "                        category_rank = fetch_rank_in_subcategory(driver, category_url, category_name, asin_list[0])\n",
    "                        if category_rank:\n",
    "                            category_ranks.append(f\"{category_rank}\")\n",
    "\n",
    "            # Format the final rank string\n",
    "            category_ranks_str = f\"({'})('.join(category_ranks)})\" if category_ranks else \"\"\n",
    "            final_rank = f\"{best_seller_rank}{category_ranks_str}\"\n",
    "\n",
    "            formatted_rank = extract_first_three_numbers(final_rank)\n",
    "            logger.info(f\"Final rank for {product} (ASIN: {asin_list[0]}): {formatted_rank}\")\n",
    "\n",
    "            update_google_sheet(product, current_time, formatted_rank)\n",
    "            return  # Exit the loop after a successful scrape\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Attempt {retries + 1} failed for {product}: {e}\")\n",
    "            retries += 1\n",
    "\n",
    "            if retries < max_retries:\n",
    "                logger.info(f\"Refreshing {product} page and retrying...\")\n",
    "                driver.refresh()  # Only refresh instead of opening a new URL\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                )\n",
    "            else:\n",
    "                logger.error(f\"Failed to scrape {product} after {max_retries} retries.\")\n",
    "                update_google_sheet(product, current_time, \"Failed to Fetch\")  # Mark failure in the sheet\n",
    "                return\n",
    "\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def scrape_wrapper(product, url, asin, options, current_time):\n",
    "    \"\"\"Wrapper function to handle multi-threaded scraping.\"\"\"\n",
    "    try:\n",
    "        driver = webdriver.Chrome(options=options)  # Initialize WebDriver inside thread\n",
    "        scrape_best_sellers_rank(driver, product, url, [asin], current_time)\n",
    "        driver.quit()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in scrape_wrapper for {product}: {e}\")\n",
    "\n",
    "def run_scrape_all():\n",
    "    \"\"\"Parallel execution for scraping multiple URLs\"\"\"\n",
    "    url_data = url_sheet.get_all_records()\n",
    "    df = pd.DataFrame(url_data)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    product_names = df['Products'].tolist()\n",
    "    url_list = df['URL'].tolist()\n",
    "    asin_list = df['ASIN'].tolist()\n",
    "    current_time = current_time_slot()\n",
    "\n",
    "    options = Options()\n",
    "    # options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "\n",
    "    num_threads = min(5, len(product_names))  # Prevent excessive threads for small data\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = {\n",
    "            executor.submit(scrape_wrapper, product, url, asin, options, current_time): product\n",
    "            for product, url, asin in zip(product_names, url_list, asin_list)\n",
    "        }\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # Raise exceptions if any\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Scraping failed for {futures[future]}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Starting the scraper for all products...\")\n",
    "    run_scrape_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0606fd5-401d-465e-b95c-e915c6abfee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
